{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2層ニューラルネットワークでMNISTを解く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from common.activations import softmax, sigmoid\n",
    "from common.grad import numerical_gradient\n",
    "from common.loss import cross_entropy_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2層ニューラルネットワーククラスに識別精度を求める関数を追加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [演習]\n",
    "* 2層ニューラルネットワーククラスに識別精度を求める関数を追加しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒント\n",
    "y = np.array([[0.1, 0.9],\n",
    "                       [0.8, 0.2],\n",
    "                       [0.3, 0.7]])\n",
    "t = np.array([[0, 1],\n",
    "                       [0, 1],\n",
    "                       [1, 0]])\n",
    "\n",
    "y = np.argmax(y, axis=1)\n",
    "print(\"argmax(y)=\", y)\n",
    "\n",
    "t = np.argmax(t, axis=1)\n",
    "print(\"argmax(t)=\", t)\n",
    "\n",
    "print(np.sum(y==t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet():\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        init_std=0.01\n",
    "        np.random.seed(1234)\n",
    "        self.params[\"W1\"] = init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params[\"b1\"] = np.zeros(hidden_size)\n",
    "        self.params[\"W2\"] = init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params[\"b2\"] = np.zeros(output_size)\n",
    "                \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        x : 入力データ\n",
    "        \"\"\"\n",
    "        W1, W2 = self.params[\"W1\"], self.params[\"W2\"]\n",
    "        b1, b2 = self.params[\"b1\"], self.params[\"b2\"]\n",
    "        \n",
    "        h1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(h1)\n",
    "        h2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(h2)\n",
    "        return y\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        \"\"\"\n",
    "        x : 入力データ\n",
    "        t : 正解データ\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        return loss\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        def f(W):\n",
    "            return self.loss(x,t)\n",
    "        grads={}\n",
    "        grads[\"W1\"] = numerical_gradient(f, self.params[\"W1\"])\n",
    "        grads[\"b1\"] = numerical_gradient(f, self.params[\"b1\"])\n",
    "        grads[\"W2\"] = numerical_gradient(f, self.params[\"W2\"])\n",
    "        grads[\"b2\"] = numerical_gradient(f, self.params[\"b2\"])\n",
    "        return grads\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        \"\"\"\n",
    "        識別精度を算出する関数\n",
    "        \"\"\"\n",
    "        y = \n",
    "        t =\n",
    "        \n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTデータの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../../mnist_data/\", one_hot=True) #パスは適宜変更する\n",
    "train = mnist.train.images\n",
    "test = mnist.test.images\n",
    "train_labels = mnist.train.labels\n",
    "test_labels = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ミニバッチ学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [演習]\n",
    "* 以下のミニバッチ学習を完成させましょう。\n",
    "* 計算の進行と共に損失が小さくなっていくことを確認する場合は、以下の条件を変更する必要があります。ただし、変更すると計算に時間がかかるようになるので、変更後の計算はご自宅で試してみてください。  \n",
    "\n",
    "    ```\n",
    "    x = train[:9,:]  \n",
    "    t = train_labels[:9,:]  \n",
    "    ecpochs = 10  \n",
    "    batch_size = 3  \n",
    "    ``` 　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = train[:9,:]\n",
    "t = train_labels[:9,:]\n",
    "\n",
    "ecpochs = 10\n",
    "batch_size = 3\n",
    "lr = 0.01\n",
    "\n",
    "# 繰り返し回数\n",
    "xsize = x.shape[0]\n",
    "iter_num = np.ceil(xsize / batch_size).astype(np.int)\n",
    "\n",
    "# 2層NNのオブジェクト生成\n",
    "tnet = TwoLayerNet(input_size=28*28, hidden_size=100, output_size=10)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "for epoch in range(ecpochs):\n",
    "    print(\"epoch=%s\"%epoch)\n",
    "    \n",
    "    # シャッフル\n",
    "    idx = np.arange(xsize)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    for it in range(iter_num):\n",
    "        \"\"\"\n",
    "        ランダムなミニバッチを順番に取り出す\n",
    "        \"\"\"\n",
    "        mask = \n",
    "    \n",
    "        # ミニバッチの生成\n",
    "        x_train = x[mask]\n",
    "        t_train = t[mask]\n",
    "        \n",
    "        # 勾配の計算\n",
    "        grads = tnet.gradient()\n",
    "\n",
    "        # パラメータの更新\n",
    "        for key in tnet.params.keys():\n",
    "    #         print(key)\n",
    "            tnet.params[key] -= \n",
    "\n",
    "    ## 学習経過の記録\n",
    "    \n",
    "    # 訓練データにおけるloss\n",
    "    train_loss.append(tnet.loss( ))\n",
    "    \n",
    "    # テストデータにおけるloss\n",
    "    test_loss.append(tnet.loss( ))\n",
    "    \n",
    "    # 訓練データにて精度を確認\n",
    "    train_accuracy.append(tnet.accuracy( ))\n",
    "\n",
    "    # テストデータにて精度を算出\n",
    "    test_accuracy.append(tnet.accuracy( ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lossのグラフ化\n",
    "df_log = pd.DataFrame({\"train_loss\":train_loss,\n",
    "             \"test_loss\":test_loss,\n",
    "             \"train_accuracy\":train_accuracy,\n",
    "             \"test_accuracy\":test_accuracy})\n",
    "df_log.plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
